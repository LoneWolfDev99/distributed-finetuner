rank=1 id=12 batch=[29, 47] batch_to_yield=[]
rank=1 id=13 batch=[31, 51] batch_to_yield=[]
self.process_index rank=1 id=13 batch=[31, 51] batch_to_yield=[31, 51]
before_yeild rank=1 id=13 batch_to_yield=[31, 51]
rank=1 index=[31, 51]-> data={'input_ids': tensor([[    1,     1,   518, 25580, 29962,  1724,   338,   278,  1571,  4842,
           578, 10696,   363, 26148, 29899,   957,  2678,   284,  1153,  4637,
         29973,   518, 29914, 25580, 29962,  1932, 15859, 26148, 29899,   957,
          2678,   284,  1153,  4637, 29892,  3013,   596,  4842,   578,   472,
          1048,   263, 29871, 29946, 29945,   304, 29871, 29953, 29900, 29899,
         12163,   929, 10696, 29889,   910,  2602, 22525,   596, 18983,   628,
           517,  4841,   901, 17583, 29889, 29871,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2],
        [    1,     1,   518, 25580, 29962,  1128,   508,   306, 16116,   304,
          4788,  1403,   403,   521,   342,  2301,  2841,   527,  5521,  2925,
         29973,   518, 29914, 25580, 29962,  1763, 16116,   521,   342,   527,
          5521,  2925, 29892,  2317,   297,   263,  3050,  1582,   411,   596,
         10188, 26148,   472, 29871, 29929, 29900, 29899, 12163,   929, 23619,
         29892,   363,   799,  1516, 15385,  2750,   278,  3050,  2557, 29889,
           402,  2705, 20793,  6375, 29892, 12515,   596,  1250,  7812, 29892,
          2745,   366,  4459,   263, 16116,   297,   596,   521,   342, 29889,
         29871,     2]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,
         0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
         1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]), 'labels': tensor([[    1,     1,   518, 25580, 29962,  1724,   338,   278,  1571,  4842,
           578, 10696,   363, 26148, 29899,   957,  2678,   284,  1153,  4637,
         29973,   518, 29914, 25580, 29962,  1932, 15859, 26148, 29899,   957,
          2678,   284,  1153,  4637, 29892,  3013,   596,  4842,   578,   472,
          1048,   263, 29871, 29946, 29945,   304, 29871, 29953, 29900, 29899,
         12163,   929, 10696, 29889,   910,  2602, 22525,   596, 18983,   628,
           517,  4841,   901, 17583, 29889, 29871,  -100,  -100,  -100,  -100,
          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
          -100,  -100],
        [    1,     1,   518, 25580, 29962,  1128,   508,   306, 16116,   304,
          4788,  1403,   403,   521,   342,  2301,  2841,   527,  5521,  2925,
         29973,   518, 29914, 25580, 29962,  1763, 16116,   521,   342,   527,
          5521,  2925, 29892,  2317,   297,   263,  3050,  1582,   411,   596,
         10188, 26148,   472, 29871, 29929, 29900, 29899, 12163,   929, 23619,
         29892,   363,   799,  1516, 15385,  2750,   278,  3050,  2557, 29889,
           402,  2705, 20793,  6375, 29892, 12515,   596,  1250,  7812, 29892,
          2745,   366,  4459,   263, 16116,   297,   596,   521,   342, 29889,
         29871,  -100]])}
/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--meta-llama--Llama-2-7b-hf/snapshots/01c7f73d771dfac7d292323805ebc428287df4f9/config.json
Model config LlamaConfig {
  "_name_or_path": "meta-llama/Llama-2-7b-hf",
  "architectures": [
    "LlamaForCausalLM"
  ],
  "attention_bias": false,
  "attention_dropout": 0.0,
  "bos_token_id": 1,
  "eos_token_id": 2,
  "hidden_act": "silu",
  "hidden_size": 4096,
  "initializer_range": 0.02,
  "intermediate_size": 11008,
  "max_position_embeddings": 4096,
  "mlp_bias": false,
  "model_type": "llama",
  "num_attention_heads": 32,
  "num_hidden_layers": 32,
  "num_key_value_heads": 32,
  "pretraining_tp": 1,
  "rms_norm_eps": 1e-05,
  "rope_scaling": null,
  "rope_theta": 10000.0,
  "tie_word_embeddings": false,
  "torch_dtype": "float16",
  "transformers_version": "4.41.2",
  "use_cache": true,
  "vocab_size": 32000
}

tokenizer config file saved in /mnt/workspace/multi-gpu-custom-trainer1/checkpoint-5/tokenizer_config.json
Special tokens file saved in /mnt/workspace/multi-gpu-custom-trainer1/checkpoint-5/special_tokens_map.json
rank=0 id=12 batch=[29, 47] batch_to_yield=[]
self.process_index rank=0 id=12 batch=[29, 47] batch_to_yield=[29, 47]
rank=0 id=13 batch=[31, 51] batch_to_yield=[29, 47]
before_yeild rank=0 id=13 batch_to_yield=[29, 47]
rank=0 index=[29, 47]-> data={'input_ids': tensor([[    1,     1,   518, 25580, 29962,  1724,   881,   590,   560, 17729,
          2602,   367,  2645,   270,   398,  1327,   514, 24817,  1627, 29879,
         29973,   518, 29914, 25580, 29962,  1932, 15859,   270,   398,  1327,
           514, 24817,  1627, 29879, 29892,  3013,   596,  7568,  5075,  8943,
           304,   278, 11904,   322,   596,   560, 17729,  3802,   304,   596,
          3573, 29889,  7338,   355,   596,  5075,  1250,  1550, 12515,   596,
           560, 17729,   297,   263,  4343,  2602, 29889, 29871,     2,     2,
             2,     2],
        [    1,     1,   518, 25580, 29962,  1128,   508,   306, 16116,   304,
          4788,  1403,   403,  1208, 29888,  2301,  2841,   527,  5521,  2925,
         29973,   518, 29914, 25580, 29962,  1763, 16116,  1208, 29888,   527,
          5521,  2925, 29892,  2317, 14870,   263, 10090,   411,   697,  3661,
          6375, 29892,   540,   295,   373,   278,  5962, 29889,   951,   273,
           964,   278, 10090, 29892, 12515,   596,  1250,  2814,  7812, 29892,
          2745,   366,  4459,   263, 16116,   297,   596,  1208, 29888, 29889,
         29871,     2]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]), 'labels': tensor([[    1,     1,   518, 25580, 29962,  1724,   881,   590,   560, 17729,
          2602,   367,  2645,   270,   398,  1327,   514, 24817,  1627, 29879,
         29973,   518, 29914, 25580, 29962,  1932, 15859,   270,   398,  1327,
           514, 24817,  1627, 29879, 29892,  3013,   596,  7568,  5075,  8943,
           304,   278, 11904,   322,   596,   560, 17729,  3802,   304,   596,
          3573, 29889,  7338,   355,   596,  5075,  1250,  1550, 12515,   596,
           560, 17729,   297,   263,  4343,  2602, 29889, 29871,  -100,  -100,
          -100,  -100],
        [    1,     1,   518, 25580, 29962,  1128,   508,   306, 16116,   304,
          4788,  1403,   403,  1208, 29888,  2301,  2841,   527,  5521,  2925,
         29973,   518, 29914, 25580, 29962,  1763, 16116,  1208, 29888,   527,
          5521,  2925, 29892,  2317, 14870,   263, 10090,   411,   697,  3661,
          6375, 29892,   540,   295,   373,   278,  5962, 29889,   951,   273,
           964,   278, 10090, 29892, 12515,   596,  1250,  2814,  7812, 29892,
          2745,   366,  4459,   263, 16116,   297,   596,  1208, 29888, 29889,
         29871,  -100]])}
rank=1 loss=2.176500082015991-> inputs={'input_ids': tensor([[    1,     1,   518, 25580, 29962,  1724,   338,   278,  1571,   330,
          6472,  2920,   363,  3802, 29899, 29887,  6472,  3856,   305,  3965,
           267, 29973,   518, 29914, 25580, 29962,  1932, 15859,  3802, 29899,
         29887,  6472,  3856,   305,  3965,   267, 29892,  2602,   596,  6567,
         10029, 17655,   307,   556,  1135, 23468, 29899,  2103, 12435, 29889,
           910,   330,  6472, 19310,  7093,   596,   534,   625,   567,   901,
          1135,   263,  3918,  3856,   305,  3965,   330,  6472, 29889, 29871,
             2,     2,     2,     2,     2,     2,     2],
        [    1,     1,   518, 25580, 29962,  1724,   338,   278,  1571,   883,
           363,  3856,   305,  3965,   267, 29973,   518, 29914, 25580, 29962,
          7326,   373,   278,  3856,   305,   411,   596,  6900, 12151,   373,
           278,  5962, 29889,   402,  6472,   278,  2594, 23468, 29899,  2103,
         12435, 29892,  5224,   372,   304,   596,  7145, 29899,   305,   342,
         29892,   322,  3965,   372,  1250,   701,  1550, 12515,   596,   560,
         29890,  1242,   472,   263, 29871, 29946, 29945, 29899, 12163,   929,
         10696,   304,   596,  3573, 29889, 29871,     2]], device='cuda:1'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,
         0, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
         1, 1, 1, 1, 1]], device='cuda:1'), 'labels': tensor([[    1,     1,   518, 25580, 29962,  1724,   338,   278,  1571,   330,
          6472,  2920,   363,  3802, 29899, 29887,  6472,  3856,   305,  3965,
           267, 29973,   518, 29914, 25580, 29962,  1932, 15859,  3802, 29899,
         29887,  6472,  3856,   305,  3965,   267, 29892,  2602,   596,  6567,
         10029, 17655,   307,   556,  1135, 23468, 29899,  2103, 12435, 29889,
           910,   330,  6472, 19310,  7093,   596,   534,   625,   567,   901,
          1135,   263,  3918,  3856,   305,  3965,   330,  6472, 29889, 29871,
          -100,  -100,  -100,  -100,  -100,  -100,  -100],
        [    1,     1,   518, 25580, 29962,  1724,   338,   278,  1571,   883,
           363,  3856,   305,  3965,   267, 29973,   518, 29914, 25580, 29962,
          7326,   373,   278,  3856,   305,   411,   596,  6900, 12151,   373,
           278,  5962, 29889,   402,  6472,   278,  2594, 23468, 29899,  2103,
         12435, 29892,  5224,   372,   304,   596,  7145, 29899,   305,   342,
         29892,   322,  3965,   372,  1250,   701,  1550, 12515,   596,   560,
         29890,  1242,   472,   263, 29871, 29946, 29945, 29899, 12163,   929,
         10696,   304,   596,  3573, 29889, 29871,  -100]], device='cuda:1')} length=2
rank=0 loss=1.687440037727356-> inputs={'input_ids': tensor([[    1,     1,   518, 25580, 29962,  1128,   881,   306, 10365,   278,
           521,   342, 17132,   746,   773,   263,   409,   630,  1948,  4933,
         29973,   518, 29914, 25580, 29962,  1932,   773,   263,   409,   630,
          1948,  4933, 29892, 10365,   278,   521,   342, 17132,   577,   393,
           372,  1791, 29879, 13016,  2197,  2750,   596,   521,   342, 29889,
         19152,   596,  1250,  7812,   322,  8206,   278,  2594,  7113,   596,
          5224,   521,   342, 29889, 29871,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2],
        [    1,     1,   518, 25580, 29962,  1724,   526,   278,  1556, 11828,
          5881,   601, 24472,  3476,   267,   363,  7688,  6410, 29973,   518,
         29914, 25580, 29962,   450,  1556, 11828,  5881,   601, 24472,  3476,
           267,   363,  7688,  6410,  3160,  2734,   373,   263,   260,   949,
         19958, 29892,  5094, 19914,   373,   263,  5073,   653,  4768,   446,
         29892,   322,   773,   263,   380,  1466, 10784,   495,   470, 22434,
           415,   936,  4933, 29889,  4525, 24472,  3476,   267,  3033,   482,
          2919,  2301,  2841,  6471,   322,   508, 12138,   263,  7282,  1353,
           310,  1208,  3842, 29892,  3907,   963,  2107,   363,  9950,  6410,
         29889,   319,   326,   304,  2189,  1438, 24472,  3476,   267,   472,
           263, 17768,   403, 26171,   363,   472,  3203, 29871, 29941, 29900,
          6233,   639,  4867, 29892,   322,  1018,   304, 11039,   403,   963,
           964,   596, 26529, 29871, 29941, 29899, 29945,  3064,   639,  4723,
         29889, 29871,     2]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,
         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0'), 'labels': tensor([[    1,     1,   518, 25580, 29962,  1128,   881,   306, 10365,   278,
           521,   342, 17132,   746,   773,   263,   409,   630,  1948,  4933,
         29973,   518, 29914, 25580, 29962,  1932,   773,   263,   409,   630,
          1948,  4933, 29892, 10365,   278,   521,   342, 17132,   577,   393,
           372,  1791, 29879, 13016,  2197,  2750,   596,   521,   342, 29889,
         19152,   596,  1250,  7812,   322,  8206,   278,  2594,  7113,   596,
          5224,   521,   342, 29889, 29871,  -100,  -100,  -100,  -100,  -100,
          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
          -100,  -100,  -100],
        [    1,     1,   518, 25580, 29962,  1724,   526,   278,  1556, 11828,
          5881,   601, 24472,  3476,   267,   363,  7688,  6410, 29973,   518,
         29914, 25580, 29962,   450,  1556, 11828,  5881,   601, 24472,  3476,
           267,   363,  7688,  6410,  3160,  2734,   373,   263,   260,   949,
         19958, 29892,  5094, 19914,   373,   263,  5073,   653,  4768,   446,
         29892,   322,   773,   263,   380,  1466, 10784,   495,   470, 22434,
           415,   936,  4933, 29889,  4525, 24472,  3476,   267,  3033,   482,
          2919,  2301,  2841,  6471,   322,   508, 12138,   263,  7282,  1353,
           310,  1208,  3842, 29892,  3907,   963,  2107,   363,  9950,  6410,
         29889,   319,   326,   304,  2189,  1438, 24472,  3476,   267,   472,
           263, 17768,   403, 26171,   363,   472,  3203, 29871, 29941, 29900,
          6233,   639,  4867, 29892,   322,  1018,   304, 11039,   403,   963,
           964,   596, 26529, 29871, 29941, 29899, 29945,  3064,   639,  4723,
         29889, 29871,  -100]], device='cuda:0')} length=2
